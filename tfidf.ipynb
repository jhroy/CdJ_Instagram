{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pan\n",
    "import numpy as np\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tousFichiers = glob.glob(\"txtMedias/*.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tousDocs = []\n",
    "for fich in tousFichiers:\n",
    "    with open(fich) as f:\n",
    "        texte = f.read()\n",
    "    tousDocs.append(texte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tousDocs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_df=.65, min_df=1, stop_words=None, use_idf=True, norm=None)\n",
    "docsTransformes = vectorizer.fit_transform(tousDocs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<32x167010 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 410395 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docsTransformes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tableauDocsTransformes = docsTransformes.toarray()\n",
    "len(tableauDocsTransformes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 2.88706965, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 3.80336038, 3.80336038,\n",
       "        3.80336038],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [8.04640365, 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tableauDocsTransformes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nomsFichCSV = [str(fich).replace(\".txt\", \".csv\").replace(\"txtMedias/\", \"csvMedias/\") for fich in tousFichiers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['csvMedias/rtl_france.csv',\n",
       " 'csvMedias/lorientlejour_olj.csv',\n",
       " 'csvMedias/lesoleildequebec.csv',\n",
       " 'csvMedias/lemondefr.csv',\n",
       " 'csvMedias/liberationfr.csv',\n",
       " 'csvMedias/tf1lejt.csv',\n",
       " 'csvMedias/lematinch.csv',\n",
       " 'csvMedias/24heuresch.csv',\n",
       " 'csvMedias/lp_lapresse.csv',\n",
       " 'csvMedias/tdgch.csv',\n",
       " 'csvMedias/lefigarofr.csv',\n",
       " 'csvMedias/jdemontreal.csv',\n",
       " 'csvMedias/radiocanadainfo.csv',\n",
       " 'csvMedias/tvanouvelles.csv',\n",
       " 'csvMedias/lciofficiel.csv',\n",
       " 'csvMedias/radiotelevisionsuisse.csv',\n",
       " 'csvMedias/bfmtv.csv',\n",
       " 'csvMedias/france24.csv',\n",
       " 'csvMedias/rtlinfobe.csv',\n",
       " 'csvMedias/journalsudouest.csv',\n",
       " 'csvMedias/ouestfrance.csv',\n",
       " 'csvMedias/ledevoir.csv',\n",
       " 'csvMedias/rfi.csv',\n",
       " 'csvMedias/franceinfo.csv',\n",
       " 'csvMedias/rtbf.csv',\n",
       " 'csvMedias/mediapart.csv',\n",
       " 'csvMedias/ledauphinelibere_.csv',\n",
       " 'csvMedias/lavoixdunord.csv',\n",
       " 'csvMedias/lemondeafrique.csv',\n",
       " 'csvMedias/lalibrebe.csv',\n",
       " 'csvMedias/letempsch.csv',\n",
       " 'csvMedias/lesoirbe.csv']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nomsFichCSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for counter, doc in enumerate(tableauDocsTransformes):\n",
    "    # construct a dataframe\n",
    "    tf_idf_tuples = list(zip(vectorizer.get_feature_names(), doc))\n",
    "    one_doc_as_df = pan.DataFrame.from_records(tf_idf_tuples, columns=['term', 'score']).sort_values(by='score', ascending=False).reset_index(drop=True)\n",
    "\n",
    "    # output to a csv using the enumerated value for the filename\n",
    "    one_doc_as_df.to_csv(nomsFichCSV[counter])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tousFichiers2 = glob.glob(\"txtMois/*.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tousDocs2 = []\n",
    "for fich in tousFichiers2:\n",
    "    with open(fich) as flagada:\n",
    "        texte = flagada.read()\n",
    "    tousDocs2.append(texte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tousDocs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vecto = TfidfVectorizer(max_df=.65, min_df=1, stop_words=None, use_idf=True, norm=None)\n",
    "docsTransfo2 = vecto.fit_transform(tousDocs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<106x169993 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 763015 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docsTransfo2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabDocsTransfo2 = docsTransfo2.toarray()\n",
    "len(tabDocsTransfo2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.34737123, 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabDocsTransfo2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "nomsFichCSV2 = [str(fich).replace(\".txt\", \".csv\").replace(\"txtMois/\", \"csvMois/\") for fich in tousFichiers2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['csvMois/2015-07.csv',\n",
       " 'csvMois/2017-02.csv',\n",
       " 'csvMois/2019-07.csv',\n",
       " 'csvMois/2019-06.csv',\n",
       " 'csvMois/2019-12.csv',\n",
       " 'csvMois/2017-03.csv',\n",
       " 'csvMois/2015-12.csv',\n",
       " 'csvMois/2015-06.csv',\n",
       " 'csvMois/2015-10.csv',\n",
       " 'csvMois/2015-04.csv',\n",
       " 'csvMois/2017-01.csv',\n",
       " 'csvMois/2019-04.csv',\n",
       " 'csvMois/2019-10.csv',\n",
       " 'csvMois/2019-11.csv',\n",
       " 'csvMois/2019-05.csv',\n",
       " 'csvMois/2015-05.csv',\n",
       " 'csvMois/2015-11.csv',\n",
       " 'csvMois/2015-01.csv',\n",
       " 'csvMois/2012-08.csv',\n",
       " 'csvMois/2019-01.csv',\n",
       " 'csvMois/2017-10.csv',\n",
       " 'csvMois/2017-04.csv',\n",
       " 'csvMois/2017-05.csv',\n",
       " 'csvMois/2017-11.csv',\n",
       " 'csvMois/2012-09.csv',\n",
       " 'csvMois/2015-02.csv',\n",
       " 'csvMois/2019-02.csv',\n",
       " 'csvMois/2017-07.csv',\n",
       " 'csvMois/2017-12.csv',\n",
       " 'csvMois/2017-06.csv',\n",
       " 'csvMois/2019-03.csv',\n",
       " 'csvMois/2015-03.csv',\n",
       " 'csvMois/2020-08.csv',\n",
       " 'csvMois/2016-09.csv',\n",
       " 'csvMois/2013-05.csv',\n",
       " 'csvMois/2013-11.csv',\n",
       " 'csvMois/2013-10.csv',\n",
       " 'csvMois/2013-04.csv',\n",
       " 'csvMois/2016-08.csv',\n",
       " 'csvMois/2013-12.csv',\n",
       " 'csvMois/2013-06.csv',\n",
       " 'csvMois/2013-07.csv',\n",
       " 'csvMois/2011-06.csv',\n",
       " 'csvMois/2013-03.csv',\n",
       " 'csvMois/2013-02.csv',\n",
       " 'csvMois/2018-09.csv',\n",
       " 'csvMois/2011-05.csv',\n",
       " 'csvMois/2014-09.csv',\n",
       " 'csvMois/2013-01.csv',\n",
       " 'csvMois/2014-08.csv',\n",
       " 'csvMois/2018-08.csv',\n",
       " 'csvMois/2020-01.csv',\n",
       " 'csvMois/2018-05.csv',\n",
       " 'csvMois/2018-11.csv',\n",
       " 'csvMois/2014-11.csv',\n",
       " 'csvMois/2014-05.csv',\n",
       " 'csvMois/2014-04.csv',\n",
       " 'csvMois/2014-10.csv',\n",
       " 'csvMois/2016-01.csv',\n",
       " 'csvMois/2018-10.csv',\n",
       " 'csvMois/2018-04.csv',\n",
       " 'csvMois/2020-02.csv',\n",
       " 'csvMois/2018-12.csv',\n",
       " 'csvMois/2018-06.csv',\n",
       " 'csvMois/2016-03.csv',\n",
       " 'csvMois/2014-06.csv',\n",
       " 'csvMois/2014-12.csv',\n",
       " 'csvMois/2014-07.csv',\n",
       " 'csvMois/2016-02.csv',\n",
       " 'csvMois/2018-07.csv',\n",
       " 'csvMois/2020-03.csv',\n",
       " 'csvMois/2020-07.csv',\n",
       " 'csvMois/2016-06.csv',\n",
       " 'csvMois/2016-12.csv',\n",
       " 'csvMois/2018-03.csv',\n",
       " 'csvMois/2014-03.csv',\n",
       " 'csvMois/2014-02.csv',\n",
       " 'csvMois/2018-02.csv',\n",
       " 'csvMois/2016-07.csv',\n",
       " 'csvMois/2020-06.csv',\n",
       " 'csvMois/2020-04.csv',\n",
       " 'csvMois/2016-11.csv',\n",
       " 'csvMois/2016-05.csv',\n",
       " 'csvMois/2013-09.csv',\n",
       " 'csvMois/2014-01.csv',\n",
       " 'csvMois/2013-08.csv',\n",
       " 'csvMois/2018-01.csv',\n",
       " 'csvMois/2016-04.csv',\n",
       " 'csvMois/2016-10.csv',\n",
       " 'csvMois/2020-05.csv',\n",
       " 'csvMois/2012-07.csv',\n",
       " 'csvMois/2012-06.csv',\n",
       " 'csvMois/2012-12.csv',\n",
       " 'csvMois/2012-04.csv',\n",
       " 'csvMois/2012-10.csv',\n",
       " 'csvMois/2017-08.csv',\n",
       " 'csvMois/2017-09.csv',\n",
       " 'csvMois/2012-11.csv',\n",
       " 'csvMois/2012-05.csv',\n",
       " 'csvMois/2012-01.csv',\n",
       " 'csvMois/2015-08.csv',\n",
       " 'csvMois/2019-08.csv',\n",
       " 'csvMois/2019-09.csv',\n",
       " 'csvMois/2015-09.csv',\n",
       " 'csvMois/2012-02.csv',\n",
       " 'csvMois/2012-03.csv']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nomsFichCSV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nomsFichCSV2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for counter, doc in enumerate(tabDocsTransfo2):\n",
    "    # construct a dataframe\n",
    "    tf_idf_tuples = list(zip(vecto.get_feature_names(), doc))\n",
    "    one_doc_as_df = pan.DataFrame.from_records(tf_idf_tuples, columns=['term', 'score']).sort_values(by='score', ascending=False).reset_index(drop=True)\n",
    "\n",
    "    # output to a csv using the enumerated value for the filename\n",
    "    one_doc_as_df.to_csv(nomsFichCSV2[counter])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
